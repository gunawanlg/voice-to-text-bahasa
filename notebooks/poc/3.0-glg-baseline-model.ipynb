{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:36px\"><b>Baseline Model Tutorial</b></span>\n",
    "\n",
    "Copyright &copy; 2020 Gunawan Lumban Gaol\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language overning permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:13.855500Z",
     "start_time": "2020-02-14T04:36:08.518000Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from ipywidgets import interact\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "print(\"tf.__version__ = \"+tf.__version__)\n",
    "\n",
    "from gurih.data.data_generator import DataGenerator, get_y_true_data_generator, validate_dataset_dir\n",
    "from gurih.models.decoder import CTCDecoder\n",
    "from gurih.models.model import BaselineASRModel\n",
    "from gurih.models.utils import CharMap, wer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set documentation directory and model weights directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:16.720500Z",
     "start_time": "2020-02-14T04:36:16.265500Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"../../models/Model010b/\"  # to store model weights\n",
    "doc_dir = \"../../docs/Model010b/\"  # to store model configuration and evaluation\n",
    "\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
    "if not os.path.exists(doc_dir): os.makedirs(doc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also specify `train`, `validation`, and `test` dataset directories. \n",
    "\n",
    "These directories should contain all `.npz` and its corresponding `.txt` transcriptions files with same naming conventions. For example if npz filename is `0.npz`, then the transcription txt filename should be `0.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:18.263000Z",
     "start_time": "2020-02-14T04:36:17.798000Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = \"../../dataset/interim/Model-010b/train/\"\n",
    "valid_dir = \"../../dataset/interim/Model-010b/valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:19.393000Z",
     "start_time": "2020-02-14T04:36:18.265500Z"
    }
   },
   "outputs": [],
   "source": [
    "validate_dataset_dir(train_dir)\n",
    "validate_dataset_dir(valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constant for ASR Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:29.573000Z",
     "start_time": "2020-02-14T04:36:29.013000Z"
    }
   },
   "outputs": [],
   "source": [
    "CHAR_TO_IDX_MAP = CharMap.CHAR_TO_IDX_MAP\n",
    "IDX_TO_CHAR_MAP = CharMap.IDX_TO_CHAR_MAP\n",
    "\n",
    "MAX_SEQ_LENGTH = 3000\n",
    "MAX_LABEL_LENGTH = 300\n",
    "BATCH_SIZE = 16\n",
    "MAX_EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and compile keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:31.970500Z",
     "start_time": "2020-02-14T04:36:30.608000Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BaselineASR = BaselineASRModel(input_shape=(MAX_SEQ_LENGTH, 39), vocab_len=len(CharMap()), dir_path=model_dir, doc_path=doc_dir)\n",
    "BaselineASR.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model output sequence length for ctc input. This is required as we are using custom `Lambda` layer inside model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:32.798000Z",
     "start_time": "2020-02-14T04:36:32.330500Z"
    }
   },
   "outputs": [],
   "source": [
    "CTC_INPUT_LENGTH = BaselineASR.model.get_layer('the_output').output.shape[1]\n",
    "CTC_INPUT_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data using `DataGenerator`. Directories must contain all `.npz` and `.txt` files required for `DataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T10:54:01.654500Z",
     "start_time": "2020-02-13T10:54:01.143500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(input_dir=train_dir,\n",
    "                                max_seq_length=MAX_SEQ_LENGTH,\n",
    "                                max_label_length=MAX_LABEL_LENGTH,\n",
    "                                ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                                char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_generator = DataGenerator(input_dir=valid_dir,\n",
    "                                     max_seq_length=MAX_SEQ_LENGTH,\n",
    "                                     max_label_length=MAX_LABEL_LENGTH,\n",
    "                                     ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                                     char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass validation generator if using `EarlyStopping` and `ModelCheckpoint` callbacks. The default `_callbacks()` method also use `CSVLogger` to write epochs output in csv file based on the documentation directory of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T05:17:30.383892Z",
     "start_time": "2020-02-12T05:17:29.798894Z"
    }
   },
   "outputs": [],
   "source": [
    "BaselineASR._callbacks(min_delta=1e-4, patience=5, save_weights_only=True)\n",
    "\n",
    "# Optionally, write your custom callbacks here\n",
    "# BaselineASR.callbacks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, retrained pretrained model by loading weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T05:17:31.545892Z",
     "start_time": "2020-02-12T05:17:30.948892Z"
    }
   },
   "outputs": [],
   "source": [
    "# filename = os.path.abspath(\"../../models/BaselineASR_f200_k11_s2_pvalid_nlstm200_ndense29.h5\") # must provide abs path\n",
    "# BaselineASR.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T09:50:21.381601Z",
     "start_time": "2020-02-12T05:17:31.548892Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BaselineASR.fit_generator(train_generator=train_generator,\n",
    "                          validation_generator=validation_generator,\n",
    "                          epochs=MAX_EPOCHS,\n",
    "#                           use_multiprocessing=False,\n",
    "#                           worker=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See and save training plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:03:33.891500Z",
     "start_time": "2020-02-14T04:03:32.649000Z"
    }
   },
   "outputs": [],
   "source": [
    "# If not retraining, history will not be available in the model.\n",
    "# BaselineASR.plot_history()\n",
    "\n",
    "# To plot using csv available from CSVLogger callback\n",
    "df_hist = pd.read_csv(doc_dir+'BaselineASR_f200_k11_s2_pvalid_nlstm200_ndense29.csv')\n",
    "df_hist.set_index('epoch', inplace=True)\n",
    "df_hist.plot(figsize=(15, 6))\n",
    "plt.savefig(doc_dir+'BaselineASR_f200_k11_s2_pvalid_nlstm200_ndense29.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you may want to serialize both the model and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:03:47.122000Z",
     "start_time": "2020-02-14T04:03:46.564500Z"
    }
   },
   "outputs": [],
   "source": [
    "# BaselineASR.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Evaluate model on validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:39:45.824500Z",
     "start_time": "2020-02-14T04:39:44.632000Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = BaselineASR\n",
    "\n",
    "model = BaselineASRModel(input_shape=(MAX_SEQ_LENGTH, 39), vocab_len=len(CharMap()), dir_path=model_dir, doc_path=doc_dir)\n",
    "model.compile()\n",
    "model.load(os.path.abspath(model_dir+\"BaselineASR_f200_k11_s2_pvalid_nlstm200_ndense29.h5\")) # must provide abs path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:39:47.974500Z",
     "start_time": "2020-02-14T02:39:47.494500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(input_dir=train_dir,\n",
    "                                max_seq_length=MAX_SEQ_LENGTH,\n",
    "                                max_label_length=MAX_LABEL_LENGTH,\n",
    "                                ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                                char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_generator = DataGenerator(input_dir=valid_dir,\n",
    "                                     max_seq_length=MAX_SEQ_LENGTH,\n",
    "                                     max_label_length=MAX_LABEL_LENGTH,\n",
    "                                     ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                                     char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & WER Evaluation\n",
    "\n",
    "Calculate model `loss` and `WER` for train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:42:04.441500Z",
     "start_time": "2020-02-14T02:39:59.312000Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss, train_ctc_matrix = model.evaluate(train_generator, low_memory=True)\n",
    "val_loss, val_ctc_matrix = model.evaluate(validation_generator, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T12:51:14.720500Z",
     "start_time": "2020-02-13T12:51:14.708500Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train\\tloss: {train_loss.mean():.3f}\\tshape: {train_loss.shape}\")\n",
    "print(f\"Valid\\tloss: {val_loss.mean():.3f}\\tshape: {val_loss.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:46:29.116500Z",
     "start_time": "2020-02-14T02:46:28.636500Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = CTCDecoder(IDX_TO_CHAR_MAP)\n",
    "decoder.fit(train_ctc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:56:53.726000Z",
     "start_time": "2020-02-14T02:49:26.896500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_true = get_y_true_data_generator(IDX_TO_CHAR_MAP, train_generator)\n",
    "train_y_preds = decoder.predict(train_ctc_matrix)\n",
    "val_y_true = get_y_true_data_generator(IDX_TO_CHAR_MAP, validation_generator)\n",
    "val_y_preds = decoder.predict(val_ctc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:57:23.576000Z",
     "start_time": "2020-02-14T02:56:53.726000Z"
    }
   },
   "outputs": [],
   "source": [
    "train_wer = wer(train_y_true, train_y_preds)\n",
    "val_wer = wer(val_y_true, val_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:57:24.111000Z",
     "start_time": "2020-02-14T02:57:23.576000Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train\\tloss: {train_loss.mean():.3f}\\twer: {train_wer:.3f}\\tshape: {train_loss.shape}\")\n",
    "print(f\"Val\\tloss: {val_loss.mean():.3f}\\twer: {val_wer:.3f}\\tshape: {val_loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save evaluation metrics to `csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T03:52:59.481500Z",
     "start_time": "2020-02-14T03:52:58.991500Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    ['train', train_loss.mean(), train_wer, train_loss.shape[0]],\n",
    "    ['val', val_loss.mean(), val_wer, val_loss.shape[0]]\n",
    "]\n",
    "df_metrics = pd.DataFrame(metrics, columns=['dataset', 'loss', 'wer', 'num'])\n",
    "df_metrics.to_csv(doc_dir+'metrics.csv', index=False, line_terminator='\\n', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Test Dataset\n",
    "\n",
    "Evaluate using test data.\n",
    "\n",
    "\\*\\***IMPORTANT NOTICE**\\*\\*: \n",
    "\n",
    "Doing this will render your test set __obsolete__ as you would've already seen the datatest set you're about to evaluate. Please make sure you have optimize `bias-variance` tradeoff of the model using `validation` dataset before doing this analysis.\n",
    "\n",
    "Choose which model you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:35.748000Z",
     "start_time": "2020-02-14T04:36:34.460500Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = BaselineASR\n",
    "\n",
    "model = BaselineASRModel(input_shape=(MAX_SEQ_LENGTH, 39), vocab_len=len(CharMap()), dir_path=model_dir, doc_path=doc_dir)\n",
    "model.compile()\n",
    "model.load(os.path.abspath(model_dir+\"BaselineASR_f200_k11_s2_pvalid_nlstm200_ndense29.h5\")) # must provide abs path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & WER Evaluation\n",
    "\n",
    "Evaluate overall `loss` calculated from test set. Use decoder to get prediction str of input sequence and calculate word error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:38.348000Z",
     "start_time": "2020-02-14T04:36:37.865500Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dir = \"../../dataset/interim/Model-010a/test/\"\n",
    "validate_dataset_dir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:40.283000Z",
     "start_time": "2020-02-14T04:36:39.700500Z"
    }
   },
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(input_dir=test_dir,\n",
    "                               max_seq_length=MAX_SEQ_LENGTH,\n",
    "                               max_label_length=MAX_LABEL_LENGTH,\n",
    "                               ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                               char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                               batch_size=8,\n",
    "                               shuffle=False) # set to False to ensure correct alignment between y_true and y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:36:51.786000Z",
     "start_time": "2020-02-14T04:36:48.455500Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_ctc_matrix = model.evaluate(test_generator, low_memory=True)\n",
    "decoder = CTCDecoder(IDX_TO_CHAR_MAP)\n",
    "decoder.fit(test_ctc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:37:03.294000Z",
     "start_time": "2020-02-14T04:36:55.376000Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = get_y_true_data_generator(IDX_TO_CHAR_MAP, test_generator)\n",
    "y_pred = decoder.predict(test_ctc_matrix)\n",
    "test_wer = wer(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:37:10.894000Z",
     "start_time": "2020-02-14T04:37:10.394000Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Test\\tloss: {test_loss.mean():.3f}\\twer: {test_wer:.3f}\\tshape: {test_loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save test metrics results. This will append to metrics files created in Model Evaluation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:02:16.862000Z",
     "start_time": "2020-02-14T04:02:16.404500Z"
    }
   },
   "outputs": [],
   "source": [
    "test_metric = ['test', test_loss.mean(), test_wer, test_loss.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T04:02:37.627000Z",
     "start_time": "2020-02-14T04:02:37.147000Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.read_csv(doc_dir+'metrics.csv')\n",
    "df_metrics.loc[len(df_metrics)] = test_metric\n",
    "df_metrics.to_csv(doc_dir+'metrics.csv', index=False, line_terminator='\\n', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Trancription Evaluation\n",
    "\n",
    "Perform deeper analysis on sample transcription output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:09.200500Z",
     "start_time": "2020-02-14T02:31:08.623000Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_test_generator = DataGenerator(input_dir=test_dir,\n",
    "                                      max_seq_length=MAX_SEQ_LENGTH,\n",
    "                                      max_label_length=MAX_LABEL_LENGTH,\n",
    "                                      ctc_input_length=CTC_INPUT_LENGTH,\n",
    "                                      char_to_idx_map=CHAR_TO_IDX_MAP,\n",
    "                                      batch_size=100000, # set large to load all or num examples you want from test_dir\n",
    "                                      shuffle=False) # set to False to ensure correct alignment between y_true and y_pred\n",
    "\n",
    "X_test = sample_test_generator[0][0]['the_input']\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "y_test = sample_test_generator[0][0]['the_labels']\n",
    "y_test = np.array([''.join([IDX_TO_CHAR_MAP[c] for c in y]).strip() for y in y_test])\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T03:34:02.448500Z",
     "start_time": "2020-02-13T03:34:01.780500Z"
    }
   },
   "source": [
    "Get the `ctc_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:10.593000Z",
     "start_time": "2020-02-14T02:31:09.200500Z"
    }
   },
   "outputs": [],
   "source": [
    "ctc_matrix = model.predict(X_test)\n",
    "decoder = CTCDecoder(IDX_TO_CHAR_MAP)\n",
    "decoder.fit(ctc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all predictions from ctc_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:15.835500Z",
     "start_time": "2020-02-14T02:31:10.593000Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = decoder.predict(ctc_matrix)\n",
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and display word error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:16.325500Z",
     "start_time": "2020-02-14T02:31:15.835500Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_choice = 1\n",
    "y_true = y_test[idx_choice]\n",
    "y_pred = y_preds[idx_choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:16.755500Z",
     "start_time": "2020-02-14T02:31:16.328000Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_true)\n",
    "print()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:22.745500Z",
     "start_time": "2020-02-14T02:31:22.255500Z"
    }
   },
   "outputs": [],
   "source": [
    "word_error_rate = wer(y_true, y_pred, write_html=True)\n",
    "print('WER %.4f %%' % word_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display prediction errors. \n",
    "* Red colors are <span style=\"background-color:rgba(255, 0, 0, 0.23)\">missing word</span>\n",
    "* Green colors are <span style=\"background-color:rgba(0, 128, 0, 0.23)\">insertion word</span>.\n",
    "* Yellow colors are <span style=\"background-color:rgba(255, 165, 0, 0.5)\">substitution word</span> and the references are in parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T02:31:30.755500Z",
     "start_time": "2020-02-14T02:31:30.263000Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"diff.html\", 'r') as f:\n",
    "    html = f.readlines()[0]\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
