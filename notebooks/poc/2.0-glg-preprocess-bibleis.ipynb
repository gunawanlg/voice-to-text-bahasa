{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:36px\"><b>Preprocess Bibleis</b></span>\n",
    "\n",
    "Copyright &copy; 2020 Gunawan Lumban Gaol\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language overning permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:46.519000Z",
     "start_time": "2020-02-14T06:31:45.509000Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Transcription for Alignment\n",
    "\n",
    "Preprocess each chapter transcription by:\n",
    "1. Splitting each sentence divided by '.'\n",
    "2. Removing any character except `\"a-z\"`, `\".\"`, `\",\"`, `\"<space>\"`,\n",
    "3. Write each of chapter verse to a `.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:46.643000Z",
     "start_time": "2020-02-14T06:31:46.519000Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../dataset/processed/bibleis_trimmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:47.272000Z",
     "start_time": "2020-02-14T06:31:47.249000Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:48.309000Z",
     "start_time": "2020-02-14T06:31:48.289000Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:49.596000Z",
     "start_time": "2020-02-14T06:31:49.576000Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_str(x):\n",
    "    return re.sub(r'[^a-zA-z.,\\n ]', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:50.266000Z",
     "start_time": "2020-02-14T06:31:50.126000Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = [x.replace('\\n\\n', ' ').lower() for x in df['chapter_string']]\n",
    "tmp = [x.replace('. ', '.\\n') for x in tmp]\n",
    "tmp = [re.sub(r'[-]', ' ', x) for x in tmp]\n",
    "tmp = [clean_str(x) for x in tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the result back in the dataframe and see example of cleaned transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:52.146000Z",
     "start_time": "2020-02-14T06:31:52.126000Z"
    }
   },
   "outputs": [],
   "source": [
    "df['chapter_string'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:52.456000Z",
     "start_time": "2020-02-14T06:31:52.442000Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(1)['chapter_string'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the cleaned transcription into `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T06:31:58.658000Z",
     "start_time": "2020-02-14T06:31:58.653000Z"
    }
   },
   "outputs": [],
   "source": [
    "# for x in df.values:\n",
    "#     with open(x[2][:-4] + '.txt', 'w', encoding='utf-8') as f:\n",
    "#         f.writelines(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Audio & Text After Alignment\n",
    "\n",
    "Given aligned `.json` from aeneas output, split each audio sentence into its own `.mp3` and `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T06:24:37.089000Z",
     "start_time": "2020-01-30T06:24:36.957000Z"
    }
   },
   "outputs": [],
   "source": [
    "from gurih.data.splitter import AeneasSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T06:25:09.492000Z",
     "start_time": "2020-01-30T06:25:09.473000Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = '../../dataset/processed/bibleis_trimmed/'\n",
    "output_dir = '../../dataset/processed/bibleis_trimmed_splitted/'\n",
    "splitter = AeneasSplitter(input_dir=input_dir, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T06:26:03.258000Z",
     "start_time": "2020-01-30T06:26:03.210000Z"
    }
   },
   "outputs": [],
   "source": [
    "aligned_jsons = glob.glob(input_dir+\"*.json\")\n",
    "aligned_jsons = [os.path.basename(path) for path in aligned_jsons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-28T06:14:12.521Z"
    }
   },
   "outputs": [],
   "source": [
    "for json in aligned_jsons:\n",
    "    fragments = splitter.load(json)\n",
    "    splitter.split_and_write(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Features\n",
    "\n",
    "Given splitted `.mp3` files, extract the features and write in `.npz` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T08:49:12.331000Z",
     "start_time": "2020-02-04T08:49:12.322000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from gurih.data.normalizer import AudioNormalizer\n",
    "from gurih.features.extractor import MFCCFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T08:49:12.466000Z",
     "start_time": "2020-02-04T08:49:12.460000Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = \"../../test/test_data/data_generator/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T08:49:15.024000Z",
     "start_time": "2020-02-04T08:49:13.115000Z"
    }
   },
   "outputs": [],
   "source": [
    "X = glob.glob(input_dir+\"*.mp3\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"normalizer\", AudioNormalizer(output_dir=input_dir)),\n",
    "        (\"mfcc_feature_extractor\", MFCCFeatureExtractor(write_output=True,\n",
    "                                                        output_dir=input_dir,\n",
    "                                                        append_delta=True))\n",
    "    ]\n",
    ")\n",
    "outputs = pipeline.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
